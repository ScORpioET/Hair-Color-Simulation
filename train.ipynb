{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44d8f391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from data.ipynb\n",
      "importing Jupyter notebook from utils.ipynb\n",
      "importing Jupyter notebook from config.ipynb\n",
      "importing Jupyter notebook from model.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from data import FaceData\n",
    "from model import UNet\n",
    "import config\n",
    "import utils\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms\n",
    "from imutils import paths\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b71f555e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52dcf1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagePaths, maskPaths = utils.get_path_list('dataset')\n",
    "\n",
    "# 依照設定的比例分割測試集和驗證集\n",
    "(trainImages, testImages) = train_test_split(imagePaths, test_size=config.TEST_SPLIT, random_state=42)\n",
    "(trainMasks, testMasks) = train_test_split(maskPaths, test_size=config.TEST_SPLIT, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f752a7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trns = transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize(config.IMAGE_RESIZE)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4aa6248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] found 24000 examples in the training set...\n",
      "[INFO] found 6000 examples in the test set...\n"
     ]
    }
   ],
   "source": [
    "trainDS = FaceData(trainImages, trainMasks, trns)\n",
    "testDS = FaceData(testImages, testMasks, trns)\n",
    "print(f\"[INFO] found {len(trainDS)} examples in the training set...\")\n",
    "print(f\"[INFO] found {len(testDS)} examples in the test set...\")\n",
    "\n",
    "trainLoader = DataLoader(trainDS, shuffle=True,\n",
    "    batch_size=config.BATCH_SIZE, pin_memory=config.PIN_MEMORY,\n",
    "    num_workers=0)\n",
    "testLoader = DataLoader(testDS, shuffle=False,\n",
    "    batch_size=config.BATCH_SIZE, pin_memory=config.PIN_MEMORY,\n",
    "    num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3017a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = UNet(config.NUM_CHANNELS, config.NUM_CLASSES).to(config.DEVICE)\n",
    "\n",
    "# if os.path.exists('./output/last_model.pth'):\n",
    "#     unet.load_state_dict(torch.load('./output/best_model.pth')['model_state_dict'])\n",
    "\n",
    "lossFunc = BCEWithLogitsLoss()\n",
    "opt = Adam(unet.parameters(), lr=config.INIT_LR, betas=(0.9, 0.999), weight_decay=0.1)\n",
    "\n",
    "trainSteps = len(trainDS) // config.BATCH_SIZE\n",
    "testSteps = len(testDS) // config.BATCH_SIZE\n",
    "# 建立字典便於追蹤loss\n",
    "H = {\"train_loss\": [], \"test_loss\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667930f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training the network...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|██████████████▋                                                                  | 68/375 [02:30<11:01,  2.15s/it]"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] training the network...\")\n",
    "\n",
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "best_val_loss = 9999\n",
    "\n",
    "startTime = time.time()\n",
    "for e in range(config.NUM_EPOCHS):\n",
    "    # 每次驗證都需要轉換為eval，訓練時要轉換回來\n",
    "    unet.train()\n",
    "    \n",
    "    totalTrainLoss = 0\n",
    "    totalTestLoss = 0\n",
    "    \n",
    "    # training\n",
    "    for (i, (images, masks)) in tqdm(enumerate(trainLoader), total=len(trainLoader)):\n",
    "        (images, masks) = (images.to(config.DEVICE), masks.to(config.DEVICE))\n",
    "        # forward pass\n",
    "        pred = unet(images)\n",
    "        # training loss\n",
    "        loss = lossFunc(pred, masks)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        # totalloss\n",
    "        totalTrainLoss += loss\n",
    "    # valid\n",
    "    with torch.no_grad():\n",
    "        unet.eval()\n",
    "        \n",
    "        for _, (images, masks) in tqdm(enumerate(testLoader), total=len(testLoader)):\n",
    "            (images, masks) = (images.to(config.DEVICE), masks.to(config.DEVICE))\n",
    "            pred = unet(images)\n",
    "            totalTestLoss += lossFunc(pred, masks)\n",
    "            \n",
    "    avgTrainLoss = totalTrainLoss / trainSteps\n",
    "    avgTestLoss = totalTestLoss / testSteps\n",
    "    # update training history\n",
    "    H[\"train_loss\"].append(avgTrainLoss.cpu().detach().numpy())\n",
    "    H[\"test_loss\"].append(avgTestLoss.cpu().detach().numpy())\n",
    "    \n",
    "    print(\"[INFO] EPOCH: {}/{}\".format(e + 1, config.NUM_EPOCHS))\n",
    "    print(\"Train loss: {:.6f}, Test loss: {:.4f}\".format(\n",
    "        avgTrainLoss, avgTestLoss))\n",
    "    \n",
    "    \n",
    "    best_val_loss = 9999\n",
    "    \n",
    "    if bestValLoss > avgTestLoss:\n",
    "        best_val_loss = avgTestLoss\n",
    "        torch.save(unet.state_dict(), 'output/best_model.pth')\n",
    "    \n",
    "    torch.save(unet.state_dict(), 'output/last_model.pth')\n",
    "    \n",
    "    utils.save_loss_plot(\n",
    "        config.BASE_OUTPUT, H[\"train_loss\"],  H[\"test_loss\"]\n",
    "    )\n",
    "    \n",
    "endTime = time.time()\n",
    "print(\"[INFO] total time taken to train the model: {:.2f}s\".format(\n",
    "    endTime - startTime))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
